{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EvzAzWJTv5j",
        "outputId": "f0008bb0-42f3-45da-85a0-a0ab067b961e"
      },
      "source": [
        "# FID 测量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-fid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 运行命令 输入生成图像的路径和原始图像的路径"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhYl-_5cT6xr",
        "outputId": "72ffff41-55f9-4d2c-f5be-9c8f2dfcd235",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!python -m pytorch_fid /content/path1 /content/path2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "refer to https://github.com/jfzhang95/pytorch-deeplab-xception/blob/master/utils/metrics.py\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "__all__ = ['SegmentationMetric']\n",
        "\n",
        "\"\"\"\n",
        "confusionMetric  # 注意：此处横着代表预测值，竖着代表真实值，与之前介绍的相反\n",
        "P\\L     P    N\n",
        "P      TP    FP\n",
        "N      FN    TN\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class SegmentationMetric(object):\n",
        "    def __init__(self, numClass):\n",
        "        self.numClass = numClass\n",
        "        self.confusionMatrix = np.zeros((self.numClass,) * 2)  # 混淆矩阵（空）\n",
        "\n",
        "    def pixelAccuracy(self):\n",
        "        # return all class overall pixel accuracy 正确的像素占总像素的比例\n",
        "        #  PA = acc = (TP + TN) / (TP + TN + FP + TN)\n",
        "        acc = np.diag(self.confusionMatrix).sum() / self.confusionMatrix.sum()\n",
        "        return acc\n",
        "\n",
        "    def classPixelAccuracy(self):\n",
        "        # return each category pixel accuracy(A more accurate way to call it precision)\n",
        "        # acc = (TP) / TP + FP\n",
        "        classAcc = np.diag(self.confusionMatrix) / self.confusionMatrix.sum(axis=1)\n",
        "        return classAcc  # 返回的是一个列表值，如：[0.90, 0.80, 0.96]，表示类别1 2 3各类别的预测准确率\n",
        "\n",
        "    def meanPixelAccuracy(self):\n",
        "        \"\"\"\n",
        "        Mean Pixel Accuracy(MPA，均像素精度)：是PA的一种简单提升，计算每个类内被正确分类像素数的比例，之后求所有类的平均。\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        classAcc = self.classPixelAccuracy()\n",
        "        meanAcc = np.nanmean(classAcc)  # np.nanmean 求平均值，nan表示遇到Nan类型，其值取为0\n",
        "        return meanAcc  # 返回单个值，如：np.nanmean([0.90, 0.80, 0.96, nan, nan]) = (0.90 + 0.80 + 0.96） / 3 =  0.89\n",
        "\n",
        "    def IntersectionOverUnion(self):\n",
        "        # Intersection = TP Union = TP + FP + FN\n",
        "        # IoU = TP / (TP + FP + FN)\n",
        "        intersection = np.diag(self.confusionMatrix)  # 取对角元素的值，返回列表\n",
        "        union = np.sum(self.confusionMatrix, axis=1) + np.sum(self.confusionMatrix, axis=0) - np.diag(\n",
        "            self.confusionMatrix)  # axis = 1表示混淆矩阵行的值，返回列表； axis = 0表示取混淆矩阵列的值，返回列表\n",
        "        IoU = intersection / union  # 返回列表，其值为各个类别的IoU\n",
        "        return IoU\n",
        "\n",
        "    def meanIntersectionOverUnion(self):\n",
        "        mIoU = np.nanmean(self.IntersectionOverUnion())  # 求各类别IoU的平均\n",
        "        return mIoU\n",
        "\n",
        "    def genConfusionMatrix(self, imgPredict, imgLabel):  #\n",
        "        \"\"\"\n",
        "        同FCN中score.py的fast_hist()函数,计算混淆矩阵\n",
        "        :param imgPredict:\n",
        "        :param imgLabel:\n",
        "        :return: 混淆矩阵\n",
        "        \"\"\"\n",
        "        # remove classes from unlabeled pixels in gt image and predict\n",
        "        mask = (imgLabel >= 0) & (imgLabel < self.numClass)\n",
        "        label = self.numClass * imgLabel[mask] + imgPredict[mask]\n",
        "        count = np.bincount(label, minlength=self.numClass ** 2)\n",
        "        confusionMatrix = count.reshape(self.numClass, self.numClass)\n",
        "        # print(confusionMatrix)\n",
        "        return confusionMatrix\n",
        "\n",
        "    def Frequency_Weighted_Intersection_over_Union(self):\n",
        "        \"\"\"\n",
        "        FWIoU，频权交并比:为MIoU的一种提升，这种方法根据每个类出现的频率为其设置权重。\n",
        "        FWIOU =     [(TP+FN)/(TP+FP+TN+FN)] *[TP / (TP + FP + FN)]\n",
        "        \"\"\"\n",
        "        freq = np.sum(self.confusion_matrix, axis=1) / np.sum(self.confusion_matrix)\n",
        "        iu = np.diag(self.confusion_matrix) / (\n",
        "                np.sum(self.confusion_matrix, axis=1) + np.sum(self.confusion_matrix, axis=0) -\n",
        "                np.diag(self.confusion_matrix))\n",
        "        FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "        return FWIoU\n",
        "\n",
        "    def addBatch(self, imgPredict, imgLabel):\n",
        "        assert imgPredict.shape == imgLabel.shape\n",
        "        self.confusionMatrix += self.genConfusionMatrix(imgPredict, imgLabel)  # 得到混淆矩阵\n",
        "        return self.confusionMatrix\n",
        "\n",
        "    def reset(self):\n",
        "        self.confusionMatrix = np.zeros((self.numClass, self.numClass))\n",
        "\n",
        "# 测试内容\n",
        "if __name__ == '__main__':\n",
        "    imgPredict = cv2.imread('1.png')\n",
        "    imgLabel = cv2.imread('2.png')\n",
        "    imgPredict = np.array(cv2.cvtColor(imgPredict, cv2.COLOR_BGR2GRAY) / 255., dtype=np.uint8)\n",
        "    imgLabel = np.array(cv2.cvtColor(imgLabel, cv2.COLOR_BGR2GRAY) / 255., dtype=np.uint8)\n",
        "    # imgPredict = np.array([0, 0, 1, 1, 2, 2])  # 可直接换成预测图片\n",
        "    # imgLabel = np.array([0, 0, 1, 1, 2, 2])  # 可直接换成标注图片\n",
        "\n",
        "    metric = SegmentationMetric(2)  # 2表示有2个分类，有几个分类就填几\n",
        "    hist = metric.addBatch(imgPredict, imgLabel)\n",
        "    pa = metric.pixelAccuracy()\n",
        "    cpa = metric.classPixelAccuracy()\n",
        "    mpa = metric.meanPixelAccuracy()\n",
        "    IoU = metric.IntersectionOverUnion()\n",
        "    mIoU = metric.meanIntersectionOverUnion()\n",
        "    print('hist is :\\n', hist)\n",
        "    print('PA is : %f' % pa)\n",
        "    print('cPA is :', cpa)  # 列表\n",
        "    print('mPA is : %f' % mpa)\n",
        "    print('IoU is : ', IoU)\n",
        "    print('mIoU is : ', mIoU)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE4_Nh1SqaU1",
        "outputId": "09b54194-6071-4180-9818-531f6c9fd2a1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!python check.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czq0iHpMtxEr",
        "outputId": "450d73ba-1329-40a9-d39f-81e4f30b391d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Read images from file.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "im1 = tf.image.decode_png('./UntitledFolder/real.png')\n",
        "im2 = tf.image.decode_png('./UntitledFolder/s.png')\n",
        "# Compute PSNR over tf.uint8 Tensors.\n",
        "psnr1 = tf.image.psnr(im1, im2, max_val=255)\n",
        "print(psnr1)\n",
        "# Compute PSNR over tf.float32 Tensors.\n",
        "im1 = tf.image.convert_image_dtype(im1, tf.float32)\n",
        "im2 = tf.image.convert_image_dtype(im2, tf.float32)\n",
        "psnr2 = tf.image.psnr(im1, im2, max_val=1.0)\n",
        "# psnr1 and psnr2 both have type tf.float32 and are almost equal.\n",
        "print(psnr2)\n",
        "print(psnr2.shape)\n",
        "print(psnr2.dtype)\n",
        "#print(psnr2.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "XkcnlXDd02VZ",
        "outputId": "1f76eeef-5510-4190-9c02-040872ee8ef7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "print(tf.version.VERSION)\n",
        "# Read images from file.\n",
        "im1 = tf.io.read_file(\"读取生成图像\")\n",
        "im2 = tf.io.read_file(\"读取原图像\")\n",
        "img1 = tf.image.decode_jpge(im1)\n",
        "img2 = tf.image.decode_jpge(im2)\n",
        "#图片的分辨率要相同，要不然会报错\n",
        "psnr1 = tf.image.psnr(img1, img2, max_val=255)\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    psnr = psnr1.eval()\n",
        "    print(psnr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sulbRd-748QT"
      },
      "source": [
        "### PSNR 和SSIM 测量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jagl1nNt6Dj",
        "outputId": "81bccc8f-8a6e-4acf-9ac2-07cfd768152d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Read images from file.\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "im1 = tf.io.read_file(\"./UntitledFolder/frankfurt_000000_000294_gtFine_labelIds_synthesized_image.png\")\n",
        "im2 = tf.io.read_file(\"./UntitledFolder/frankfurt_000000_000294_leftImg8bit_1.png\")\n",
        "im1 = tf.image.decode_png(im1)\n",
        "im2 = tf.image.decode_png(im2)\n",
        "# Compute SSIM over tf.uint8 Tensors.\n",
        "ssim1 = tf.image.ssim(im1, im2, max_val=255)\n",
        "print(ssim1)\n",
        "# Compute SSIM over tf.float32 Tensors.\n",
        "im1 = tf.image.convert_image_dtype(im1, tf.float32)\n",
        "im2 = tf.image.convert_image_dtype(im2, tf.float32)\n",
        "ssim2 = tf.image.ssim(im1, im2, max_val=1.0)\n",
        "print(ssim2)\n",
        "# ssim1 and ssim2 both have type tf.float32 and are almost equal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_F9P1l54-ql",
        "outputId": "c0fef541-ffc5-4707-cdc9-fe0ebbb208c7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.clock()\n",
        "\n",
        "\n",
        "# 当中是你的程序\n",
        "\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = np.mean((img1 / 1. - img2 / 1.) ** 2)\n",
        "    if mse < 1.0e-10:\n",
        "        return 100 * 1.0\n",
        "    return 10 * math.log10(255.0 * 255.0 / mse)\n",
        "\n",
        "\n",
        "def mse(img1, img2):\n",
        "    mse = np.mean((img1 / 1. - img2 / 1.) ** 2)\n",
        "    return mse\n",
        "\n",
        "\n",
        "def ssim(y_true, y_pred):\n",
        "    u_true = np.mean(y_true)\n",
        "    u_pred = np.mean(y_pred)\n",
        "    var_true = np.var(y_true)\n",
        "    var_pred = np.var(y_pred)\n",
        "    std_true = np.sqrt(var_true)\n",
        "    std_pred = np.sqrt(var_pred)\n",
        "    c1 = np.square(0.01 * 7)\n",
        "    c2 = np.square(0.03 * 7)\n",
        "    ssim = (2 * u_true * u_pred + c1) * (2 * std_pred * std_true + c2)\n",
        "    denom = (u_true ** 2 + u_pred ** 2 + c1) * (var_pred + var_true + c2)\n",
        "    return ssim / denom\n",
        "\n",
        "\n",
        "path1 = '/content/png/'  # 指定输出结果文件夹\n",
        "path2 = '/content/png2/'  # 指定原图文件夹\n",
        "f_nums = len(os.listdir(path1))\n",
        "list_psnr = []\n",
        "list_ssim = []\n",
        "list_mse = []\n",
        "for i in range(0, 1):\n",
        "\n",
        "    img_a = Image.open(path1 + str(i) + '.png')\n",
        "    img_b = Image.open(path2 + str(i) + '.png')\n",
        "    img_a = np.array(img_a)\n",
        "    img_b = np.array(img_b)\n",
        "\n",
        "    psnr_num = psnr(img_a, img_b)\n",
        "    ssim_num = ssim(img_a, img_b)\n",
        "    mse_num = mse(img_a, img_b)\n",
        "    list_ssim.append(ssim_num)\n",
        "    list_psnr.append(psnr_num)\n",
        "    list_mse.append(mse_num)\n",
        "print(\"平均PSNR:\", np.mean(list_psnr))  # ,list_psnr)\n",
        "print(\"平均SSIM:\", np.mean(list_ssim))  # ,list_ssim)\n",
        "print(\"平均MSE:\", np.mean(list_mse))  # ,list_mse)\n",
        "\n",
        "elapsed = (time.clock() - start)\n",
        "print(\"Time used:\", elapsed)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "欢迎使用 Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
