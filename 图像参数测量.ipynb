{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2100877953/work/blob/main/%E5%9B%BE%E5%83%8F%E5%8F%82%E6%95%B0%E6%B5%8B%E9%87%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EvzAzWJTv5j",
        "outputId": "f0008bb0-42f3-45da-85a0-a0ab067b961e"
      },
      "source": [
        "# FID 测量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "owq_-ScSgpFh",
        "outputId": "93d42959-6448-49e8-8d03-65eb3d17f5de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch-fid-0.2.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->pytorch-fid) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.2.2->pytorch-fid) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->pytorch-fid) (2021.10.8)\n",
            "Building wheels for collected packages: pytorch-fid\n",
            "  Building wheel for pytorch-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-fid: filename=pytorch_fid-0.2.1-py3-none-any.whl size=14835 sha256=cad04855882e540a81e1933488efd3c50ceb25919d54804f958e3daf7b216e3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/ac/03/c5634775c8a64f702343ef5923278f8d3bb8c651debc4a6890\n",
            "Successfully built pytorch-fid\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-fid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmc_oR1NgpFj"
      },
      "source": [
        "## 运行命令 输入生成图像的路径和原始图像的路径"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhYl-_5cT6xr",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "4eb52a28-f487-47aa-dd2d-c06b2fdec69b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n",
            "\r  0% 0/1 [00:00<?, ?it/s]\r100% 1/1 [00:00<00:00,  4.89it/s]\r100% 1/1 [00:00<00:00,  3.95it/s]\n",
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n",
            "100% 1/1 [00:00<00:00,  5.60it/s]\n",
            "FID:  173.19822661973876\n"
          ]
        }
      ],
      "source": [
        "!python -m pytorch_fid /content/real /content/fake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-fidelity#KID \n",
        "#使用 0号GPU加速计算 \n",
        "fidelity --gpu 0 --isc --input1 img_dir1/\n",
        "\n",
        "#使用 0,1,2,3号GPU加速计算   这个貌似没用  还是在用一个gpu计算\n",
        "fidelity --gpu 0,1,2,3 --isc --input1 img_dir1/\n",
        "\n",
        "#FID\n",
        "fidelity --gpu 0 --fid --input1 img_dir1/ --input2 img_dir2/\n",
        "\n",
        "#KID\n",
        "fidelity --gpu 0 --kid --input1 img_dir1/ --input2 img_dir2/\n"
      ],
      "metadata": {
        "id": "ynxMkp5RwOAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.12.0.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data\n",
        "\n",
        "from torchvision.models.inception import inception_v3\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
        "    \"\"\"Computes the inception score of the generated images imgs\n",
        "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
        "    cuda -- whether or not to run on GPU\n",
        "    batch_size -- batch size for feeding into Inception v3\n",
        "    splits -- number of splits\n",
        "    \"\"\"\n",
        "    N = len(imgs)\n",
        "\n",
        "    assert batch_size > 0\n",
        "    assert N > batch_size\n",
        "\n",
        "    # Set up dtype\n",
        "    if cuda:\n",
        "        dtype = torch.cuda.FloatTensor\n",
        "    else:\n",
        "        if torch.cuda.is_available():\n",
        "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
        "        dtype = torch.FloatTensor\n",
        "\n",
        "    # Set up dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
        "\n",
        "    # Load inception model\n",
        "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
        "    inception_model.eval();\n",
        "    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
        "    def get_pred(x):\n",
        "        if resize:\n",
        "            x = up(x)\n",
        "        x = inception_model(x)\n",
        "        return F.softmax(x).data.cpu().numpy()\n",
        "\n",
        "    # Get predictions\n",
        "    preds = np.zeros((N, 1000))\n",
        "\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "        batch = batch.type(dtype)\n",
        "        batchv = Variable(batch)\n",
        "        batch_size_i = batch.size()[0]\n",
        "\n",
        "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
        "\n",
        "    # Now compute the mean kl-div\n",
        "    split_scores = []\n",
        "\n",
        "    for k in range(splits):\n",
        "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
        "        py = np.mean(part, axis=0)\n",
        "        scores = []\n",
        "        for i in range(part.shape[0]):\n",
        "            pyx = part[i, :]\n",
        "            scores.append(entropy(pyx, py))\n",
        "        split_scores.append(np.exp(np.mean(scores)))\n",
        "\n",
        "    return np.mean(split_scores), np.std(split_scores)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    class IgnoreLabelDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, orig):\n",
        "            self.orig = orig\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            return self.orig[index][0]\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.orig)\n",
        "\n",
        "    import torchvision.datasets as dset\n",
        "    import torchvision.transforms as transforms\n",
        "    # torchvision==0.12.0.\n",
        "    cifar = dset.CIFAR10(root='/content/data', download=True,\n",
        "                             transform=transforms.Compose([\n",
        "                                 transforms.Resize(32),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                             ])\n",
        "    )\n",
        "\n",
        "    IgnoreLabelDataset(cifar)\n",
        "\n",
        "    print (\"Calculating Inception Score...\")\n",
        "    print (inception_score(IgnoreLabelDataset(cifar), cuda=True, batch_size=32, resize=True, splits=10))"
      ],
      "metadata": {
        "id": "0togWOZRh6Wv",
        "outputId": "7751f6f6-9b7c-4948-913b-92c5b13e0d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "dea89fbd310e459fb11fe73a4412528b",
            "5f7194b23ab14bd3a17489ab17c823b1",
            "28c246d2b41044babe2d0dbcf4a76c64",
            "74aec3f3f41448feabc5960d69eebd9f",
            "f30a9f0b1a714d74a93b7b5cf920c096",
            "50c3e84b40df4a5e80885e68286710ef",
            "f61915d6d3a2420eb4c136d752389a5a",
            "eeff8365b3354234a3a9a31842b4dd4c",
            "51f033b930784244b016102eceffcc50",
            "daca15f285e745bd80a44bba9dae46f4",
            "f528586f48cd4be6ac8d405ea1efee05",
            "2c0af5fd11f54386a6d6e2258365538f",
            "333c305399ab47e4b651bb262ba1d249",
            "c147488b8b7f4c89a269b1ea89030e2c",
            "704dff712bc3438f92dee943261eb6b2",
            "e08cc783c74a4f9cb92e30dbb04e027d",
            "a76277b6285447479b088086a4c693f2",
            "666520bfeae14003a90fa48705e3bf11",
            "131ebfb6c08d4cb3a5e9c1b75828296b",
            "d51e371d127a4f419c6e18a89e01c7f8",
            "3708251ec3aa43eaa98995e679b48c9a",
            "8f155570943741eaa1cf30100ed8ac07"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision==0.12.0. in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0.) (4.2.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0.) (1.11.0+cu113)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0.) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0.) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0.) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0.) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0.) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0.) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0.) (3.0.4)\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/real/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dea89fbd310e459fb11fe73a4412528b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/real/cifar-10-python.tar.gz to /content/real\n",
            "Calculating Inception Score...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/104M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c0af5fd11f54386a6d6e2258365538f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9.672780773421911, 0.1499181153374744)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.12.0.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data\n",
        "\n",
        "from torchvision.models.inception import inception_v3\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
        "    \"\"\"Computes the inception score of the generated images imgs\n",
        "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
        "    cuda -- whether or not to run on GPU\n",
        "    batch_size -- batch size for feeding into Inception v3\n",
        "    splits -- number of splits\n",
        "    \"\"\"\n",
        "    N = len(imgs)\n",
        "\n",
        "    assert batch_size > 0\n",
        "    assert N > batch_size\n",
        "\n",
        "    # Set up dtype\n",
        "    if cuda:\n",
        "        dtype = torch.cuda.FloatTensor\n",
        "    else:\n",
        "        if torch.cuda.is_available():\n",
        "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
        "        dtype = torch.FloatTensor\n",
        "\n",
        "    # Set up dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
        "\n",
        "    # Load inception model\n",
        "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
        "    inception_model.eval();\n",
        "    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
        "    def get_pred(x):\n",
        "        if resize:\n",
        "            x = up(x)\n",
        "        x = inception_model(x)\n",
        "        return F.softmax(x).data.cpu().numpy()\n",
        "\n",
        "    # Get predictions\n",
        "    preds = np.zeros((N, 1000))\n",
        "\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "        batch = batch.type(dtype)\n",
        "        batchv = Variable(batch)\n",
        "        batch_size_i = batch.size()[0]\n",
        "\n",
        "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
        "\n",
        "    # Now compute the mean kl-div\n",
        "    split_scores = []\n",
        "\n",
        "    for k in range(splits):\n",
        "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
        "        py = np.mean(part, axis=0)\n",
        "        scores = []\n",
        "        for i in range(part.shape[0]):\n",
        "            pyx = part[i, :]\n",
        "            scores.append(entropy(pyx, py))\n",
        "        split_scores.append(np.exp(np.mean(scores)))\n",
        "\n",
        "    return np.mean(split_scores), np.std(split_scores)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    class IgnoreLabelDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, orig):\n",
        "            self.orig = orig\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            return self.orig[index][0]\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.orig)\n",
        "\n",
        "    import torchvision.datasets as dset\n",
        "    import torchvision.transforms as transforms\n",
        "    # torchvision==0.12.0.\n",
        "    cifar = dset.CIFAR10(root='/content/data', download=True,\n",
        "                             transform=transforms.Compose([\n",
        "                                 transforms.Resize(32),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                             ])\n",
        "    )\n",
        "\n",
        "    IgnoreLabelDataset(cifar)\n",
        "\n",
        "    print (\"Calculating Inception Score...\")\n",
        "    print (inception_score(IgnoreLabelDataset(cifar), cuda=True, batch_size=32, resize=True, splits=10))"
      ],
      "metadata": {
        "id": "Ld6PIsZap1Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "bBYVlwVYgpFk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "refer to https://github.com/jfzhang95/pytorch-deeplab-xception/blob/master/utils/metrics.py\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "__all__ = ['SegmentationMetric']\n",
        "\n",
        "\"\"\"\n",
        "confusionMetric  # 注意：此处横着代表预测值，竖着代表真实值，与之前介绍的相反\n",
        "P\\L     P    N\n",
        "P      TP    FP\n",
        "N      FN    TN\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class SegmentationMetric(object):\n",
        "    def __init__(self, numClass):\n",
        "        self.numClass = numClass\n",
        "        self.confusionMatrix = np.zeros((self.numClass,) * 2)  # 混淆矩阵（空）\n",
        "\n",
        "    def pixelAccuracy(self):\n",
        "        # return all class overall pixel accuracy 正确的像素占总像素的比例\n",
        "        #  PA = acc = (TP + TN) / (TP + TN + FP + TN)\n",
        "        acc = np.diag(self.confusionMatrix).sum() / self.confusionMatrix.sum()\n",
        "        return acc\n",
        "\n",
        "    def classPixelAccuracy(self):\n",
        "        # return each category pixel accuracy(A more accurate way to call it precision)\n",
        "        # acc = (TP) / TP + FP\n",
        "        classAcc = np.diag(self.confusionMatrix) / self.confusionMatrix.sum(axis=1)\n",
        "        return classAcc  # 返回的是一个列表值，如：[0.90, 0.80, 0.96]，表示类别1 2 3各类别的预测准确率\n",
        "\n",
        "    def meanPixelAccuracy(self):\n",
        "        \"\"\"\n",
        "        Mean Pixel Accuracy(MPA，均像素精度)：是PA的一种简单提升，计算每个类内被正确分类像素数的比例，之后求所有类的平均。\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        classAcc = self.classPixelAccuracy()\n",
        "        meanAcc = np.nanmean(classAcc)  # np.nanmean 求平均值，nan表示遇到Nan类型，其值取为0\n",
        "        return meanAcc  # 返回单个值，如：np.nanmean([0.90, 0.80, 0.96, nan, nan]) = (0.90 + 0.80 + 0.96） / 3 =  0.89\n",
        "\n",
        "    def IntersectionOverUnion(self):\n",
        "        # Intersection = TP Union = TP + FP + FN\n",
        "        # IoU = TP / (TP + FP + FN)\n",
        "        intersection = np.diag(self.confusionMatrix)  # 取对角元素的值，返回列表\n",
        "        union = np.sum(self.confusionMatrix, axis=1) + np.sum(self.confusionMatrix, axis=0) - np.diag(\n",
        "            self.confusionMatrix)  # axis = 1表示混淆矩阵行的值，返回列表； axis = 0表示取混淆矩阵列的值，返回列表\n",
        "        IoU = intersection / union  # 返回列表，其值为各个类别的IoU\n",
        "        return IoU\n",
        "\n",
        "    def meanIntersectionOverUnion(self):\n",
        "        mIoU = np.nanmean(self.IntersectionOverUnion())  # 求各类别IoU的平均\n",
        "        return mIoU\n",
        "\n",
        "    def genConfusionMatrix(self, imgPredict, imgLabel):  #\n",
        "        \"\"\"\n",
        "        同FCN中score.py的fast_hist()函数,计算混淆矩阵\n",
        "        :param imgPredict:\n",
        "        :param imgLabel:\n",
        "        :return: 混淆矩阵\n",
        "        \"\"\"\n",
        "        # remove classes from unlabeled pixels in gt image and predict\n",
        "        mask = (imgLabel >= 0) & (imgLabel < self.numClass)\n",
        "        label = self.numClass * imgLabel[mask] + imgPredict[mask]\n",
        "        count = np.bincount(label, minlength=self.numClass ** 2)\n",
        "        confusionMatrix = count.reshape(self.numClass, self.numClass)\n",
        "        # print(confusionMatrix)\n",
        "        return confusionMatrix\n",
        "\n",
        "    def Frequency_Weighted_Intersection_over_Union(self):\n",
        "        \"\"\"\n",
        "        FWIoU，频权交并比:为MIoU的一种提升，这种方法根据每个类出现的频率为其设置权重。\n",
        "        FWIOU =     [(TP+FN)/(TP+FP+TN+FN)] *[TP / (TP + FP + FN)]\n",
        "        \"\"\"\n",
        "        freq = np.sum(self.confusion_matrix, axis=1) / np.sum(self.confusion_matrix)\n",
        "        iu = np.diag(self.confusion_matrix) / (\n",
        "                np.sum(self.confusion_matrix, axis=1) + np.sum(self.confusion_matrix, axis=0) -\n",
        "                np.diag(self.confusion_matrix))\n",
        "        FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "        return FWIoU\n",
        "\n",
        "    def addBatch(self, imgPredict, imgLabel):\n",
        "        assert imgPredict.shape == imgLabel.shape\n",
        "        self.confusionMatrix += self.genConfusionMatrix(imgPredict, imgLabel)  # 得到混淆矩阵\n",
        "        return self.confusionMatrix\n",
        "\n",
        "    def reset(self):\n",
        "        self.confusionMatrix = np.zeros((self.numClass, self.numClass))\n",
        "\n",
        "# 测试内容\n",
        "if __name__ == '__main__':\n",
        "    imgPredict = cv2.imread('1.png')\n",
        "    imgLabel = cv2.imread('2.png')\n",
        "    imgPredict = np.array(cv2.cvtColor(imgPredict, cv2.COLOR_BGR2GRAY) / 255., dtype=np.uint8)\n",
        "    imgLabel = np.array(cv2.cvtColor(imgLabel, cv2.COLOR_BGR2GRAY) / 255., dtype=np.uint8)\n",
        "    # imgPredict = np.array([0, 0, 1, 1, 2, 2])  # 可直接换成预测图片\n",
        "    # imgLabel = np.array([0, 0, 1, 1, 2, 2])  # 可直接换成标注图片\n",
        "\n",
        "    metric = SegmentationMetric(2)  # 2表示有2个分类，有几个分类就填几\n",
        "    hist = metric.addBatch(imgPredict, imgLabel)\n",
        "    pa = metric.pixelAccuracy()\n",
        "    cpa = metric.classPixelAccuracy()\n",
        "    mpa = metric.meanPixelAccuracy()\n",
        "    IoU = metric.IntersectionOverUnion()\n",
        "    mIoU = metric.meanIntersectionOverUnion()\n",
        "    print('hist is :\\n', hist)\n",
        "    print('PA is : %f' % pa)\n",
        "    print('cPA is :', cpa)  # 列表\n",
        "    print('mPA is : %f' % mpa)\n",
        "    print('IoU is : ', IoU)\n",
        "    print('mIoU is : ', mIoU)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE4_Nh1SqaU1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!python check.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czq0iHpMtxEr",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Read images from file.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "im1 = tf.image.decode_png('./UntitledFolder/real.png')\n",
        "im2 = tf.image.decode_png('./UntitledFolder/s.png')\n",
        "# Compute PSNR over tf.uint8 Tensors.\n",
        "psnr1 = tf.image.psnr(im1, im2, max_val=255)\n",
        "print(psnr1)\n",
        "# Compute PSNR over tf.float32 Tensors.\n",
        "im1 = tf.image.convert_image_dtype(im1, tf.float32)\n",
        "im2 = tf.image.convert_image_dtype(im2, tf.float32)\n",
        "psnr2 = tf.image.psnr(im1, im2, max_val=1.0)\n",
        "# psnr1 and psnr2 both have type tf.float32 and are almost equal.\n",
        "print(psnr2)\n",
        "print(psnr2.shape)\n",
        "print(psnr2.dtype)\n",
        "#print(psnr2.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkcnlXDd02VZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "print(tf.version.VERSION)\n",
        "# Read images from file.\n",
        "im1 = tf.io.read_file(\"读取生成图像\")\n",
        "im2 = tf.io.read_file(\"读取原图像\")\n",
        "img1 = tf.image.decode_jpge(im1)\n",
        "img2 = tf.image.decode_jpge(im2)\n",
        "#图片的分辨率要相同，要不然会报错\n",
        "psnr1 = tf.image.psnr(img1, img2, max_val=255)\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    psnr = psnr1.eval()\n",
        "    print(psnr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sulbRd-748QT"
      },
      "source": [
        "### PSNR 和SSIM 测量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jagl1nNt6Dj",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Read images from file.\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "im1 = tf.io.read_file(\"./UntitledFolder/frankfurt_000000_000294_gtFine_labelIds_synthesized_image.png\")\n",
        "im2 = tf.io.read_file(\"./UntitledFolder/frankfurt_000000_000294_leftImg8bit_1.png\")\n",
        "im1=tf.io.decode_jpeg(\n",
        "    im1,\n",
        "    channels=0,\n",
        "    ratio=1,\n",
        "    fancy_upscaling=True,\n",
        "    try_recover_truncated=False,\n",
        "    acceptable_fraction=1,\n",
        "    dct_method='',\n",
        "    name=None\n",
        ")\n",
        "im2=tf.io.decode_jpeg(\n",
        "    im2,\n",
        "    channels=0,\n",
        "    ratio=1,\n",
        "    fancy_upscaling=True,\n",
        "    try_recover_truncated=False,\n",
        "    acceptable_fraction=1,\n",
        "    dct_method='',\n",
        "    name=None\n",
        ")\n",
        "#im1 = tf.image.decode_png(im1)\n",
        "#im2 = tf.image.decode_png(im2)\n",
        "# Compute SSIM over tf.uint8 Tensors.\n",
        "ssim1 = tf.image.ssim(im1, im2, max_val=255)\n",
        "print(ssim1)\n",
        "# Compute SSIM over tf.float32 Tensors.\n",
        "im1 = tf.image.convert_image_dtype(im1, tf.float32)\n",
        "im2 = tf.image.convert_image_dtype(im2, tf.float32)\n",
        "ssim2 = tf.image.ssim(im1, im2, max_val=1.0)\n",
        "print(ssim2)\n",
        "# ssim1 and ssim2 both have type tf.float32 and are almost equal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_F9P1l54-ql",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.clock()\n",
        "\n",
        "\n",
        "# 当中是你的程序\n",
        "\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = np.mean((img1 / 1. - img2 / 1.) ** 2)\n",
        "    if mse < 1.0e-10:\n",
        "        return 100 * 1.0\n",
        "    return 10 * math.log10(255.0 * 255.0 / mse)\n",
        "\n",
        "\n",
        "def mse(img1, img2):\n",
        "    mse = np.mean((img1 / 1. - img2 / 1.) ** 2)\n",
        "    return mse\n",
        "\n",
        "\n",
        "def ssim(y_true, y_pred):\n",
        "    u_true = np.mean(y_true)\n",
        "    u_pred = np.mean(y_pred)\n",
        "    var_true = np.var(y_true)\n",
        "    var_pred = np.var(y_pred)\n",
        "    std_true = np.sqrt(var_true)\n",
        "    std_pred = np.sqrt(var_pred)\n",
        "    c1 = np.square(0.01 * 7)\n",
        "    c2 = np.square(0.03 * 7)\n",
        "    ssim = (2 * u_true * u_pred + c1) * (2 * std_pred * std_true + c2)\n",
        "    denom = (u_true ** 2 + u_pred ** 2 + c1) * (var_pred + var_true + c2)\n",
        "    return ssim / denom\n",
        "\n",
        "\n",
        "path1 = '/content/png/'  # 指定输出结果文件夹\n",
        "path2 = '/content/png2/'  # 指定原图文件夹\n",
        "f_nums = len(os.listdir(path1))\n",
        "list_psnr = []\n",
        "list_ssim = []\n",
        "list_mse = []\n",
        "for i in range(0, 1):\n",
        "\n",
        "    img_a = Image.open(path1 + str(i) + '.png')\n",
        "    img_b = Image.open(path2 + str(i) + '.png')\n",
        "    img_a = np.array(img_a)\n",
        "    img_b = np.array(img_b)\n",
        "\n",
        "    psnr_num = psnr(img_a, img_b)\n",
        "    ssim_num = ssim(img_a, img_b)\n",
        "    mse_num = mse(img_a, img_b)\n",
        "    list_ssim.append(ssim_num)\n",
        "    list_psnr.append(psnr_num)\n",
        "    list_mse.append(mse_num)\n",
        "print(\"平均PSNR:\", np.mean(list_psnr))  # ,list_psnr)\n",
        "print(\"平均SSIM:\", np.mean(list_ssim))  # ,list_ssim)\n",
        "print(\"平均MSE:\", np.mean(list_mse))  # ,list_mse)\n",
        "\n",
        "elapsed = (time.clock() - start)\n",
        "print(\"Time used:\", elapsed)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data\n",
        "\n",
        "from torchvision.models.inception import inception_v3\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "import os \n",
        "import pathlib\n",
        "import argparse\n",
        "from PIL import Image\n",
        "\n",
        "def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
        "    \"\"\"Computes the inception score of the generated images imgs\n",
        "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
        "    cuda -- whether or not to run on GPU\n",
        "    batch_size -- batch size for feeding into Inception v3\n",
        "    splits -- number of splits\n",
        "    \"\"\"\n",
        "    N = len(imgs)\n",
        "\n",
        "    assert batch_size > 0\n",
        "    assert N > batch_size\n",
        "\n",
        "    # Set up dtype\n",
        "    if cuda:\n",
        "        dtype = torch.cuda.FloatTensor\n",
        "    else:\n",
        "        if torch.cuda.is_available():\n",
        "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
        "        dtype = torch.FloatTensor\n",
        "\n",
        "    # Set up dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
        "\n",
        "    # Load inception model\n",
        "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
        "    inception_model.eval()\n",
        "    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
        "    def get_pred(x):\n",
        "        if resize:\n",
        "            x = up(x)\n",
        "        x = inception_model(x)\n",
        "        return F.softmax(x).data.cpu().numpy()\n",
        "\n",
        "    # Get predictions\n",
        "    preds = np.zeros((N, 1000))\n",
        "\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "        batch = batch.type(dtype)\n",
        "        batchv = Variable(batch)\n",
        "        batch_size_i = batch.size()[0]\n",
        "\n",
        "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
        "\n",
        "    # Now compute the mean kl-div\n",
        "    split_scores = []\n",
        "\n",
        "    for k in range(splits):\n",
        "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
        "        py = np.mean(part, axis=0)\n",
        "        scores = []\n",
        "        for i in range(part.shape[0]):\n",
        "            pyx = part[i, :]\n",
        "            scores.append(entropy(pyx, py))\n",
        "        split_scores.append(np.exp(np.mean(scores)))\n",
        "\n",
        "    return np.mean(split_scores), np.std(split_scores)\n",
        "\n",
        "class IgnoreLabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, orig):\n",
        "        self.orig = orig\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.orig[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.orig)\n",
        "\n",
        "def read_data(pred_path):\n",
        "    pred = []\n",
        "    path = pathlib.Path(pred_path)\n",
        "    files = list(path.glob('*.jpg')) + list(path.glob('*.png'))\n",
        "    # num = len(files)\n",
        "\n",
        "    for name in files:\n",
        "        pred.append(np.asarray(Image.open(os.path.join(pred_path, name))))\n",
        "\n",
        "    pred = np.asarray(pred)\n",
        "    # if images are gray\n",
        "    if len(pred.shape) == 3:\n",
        "        pred = pred[:,:,:,np.newaxis]\n",
        "        pred = np.concatenate([pred,pred,pred], axis=3)\n",
        "    pred = pred.transpose((0, 3, 1, 2))\n",
        "    pred = pred.astype(np.float32) / 255.0\n",
        "\n",
        "    return pred\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-p', '--path', type=str, default=None)\n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    print('Read data...')\n",
        "    data = read_data(args.path)\n",
        "\n",
        "    ite_data = IgnoreLabelDataset(data)\n",
        "\n",
        "    print (\"Calculating Inception Score...\")\n",
        "    print (inception_score(ite_data, cuda=True, batch_size=10, resize=True, splits=10))\n"
      ],
      "metadata": {
        "id": "AsVrAdDmxZEI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "欢迎使用 Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dea89fbd310e459fb11fe73a4412528b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f7194b23ab14bd3a17489ab17c823b1",
              "IPY_MODEL_28c246d2b41044babe2d0dbcf4a76c64",
              "IPY_MODEL_74aec3f3f41448feabc5960d69eebd9f"
            ],
            "layout": "IPY_MODEL_f30a9f0b1a714d74a93b7b5cf920c096"
          }
        },
        "5f7194b23ab14bd3a17489ab17c823b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50c3e84b40df4a5e80885e68286710ef",
            "placeholder": "​",
            "style": "IPY_MODEL_f61915d6d3a2420eb4c136d752389a5a",
            "value": ""
          }
        },
        "28c246d2b41044babe2d0dbcf4a76c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeff8365b3354234a3a9a31842b4dd4c",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51f033b930784244b016102eceffcc50",
            "value": 170498071
          }
        },
        "74aec3f3f41448feabc5960d69eebd9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daca15f285e745bd80a44bba9dae46f4",
            "placeholder": "​",
            "style": "IPY_MODEL_f528586f48cd4be6ac8d405ea1efee05",
            "value": " 170499072/? [00:02&lt;00:00, 74398140.63it/s]"
          }
        },
        "f30a9f0b1a714d74a93b7b5cf920c096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c3e84b40df4a5e80885e68286710ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61915d6d3a2420eb4c136d752389a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeff8365b3354234a3a9a31842b4dd4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f033b930784244b016102eceffcc50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "daca15f285e745bd80a44bba9dae46f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f528586f48cd4be6ac8d405ea1efee05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c0af5fd11f54386a6d6e2258365538f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_333c305399ab47e4b651bb262ba1d249",
              "IPY_MODEL_c147488b8b7f4c89a269b1ea89030e2c",
              "IPY_MODEL_704dff712bc3438f92dee943261eb6b2"
            ],
            "layout": "IPY_MODEL_e08cc783c74a4f9cb92e30dbb04e027d"
          }
        },
        "333c305399ab47e4b651bb262ba1d249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a76277b6285447479b088086a4c693f2",
            "placeholder": "​",
            "style": "IPY_MODEL_666520bfeae14003a90fa48705e3bf11",
            "value": "100%"
          }
        },
        "c147488b8b7f4c89a269b1ea89030e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_131ebfb6c08d4cb3a5e9c1b75828296b",
            "max": 108949747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d51e371d127a4f419c6e18a89e01c7f8",
            "value": 108949747
          }
        },
        "704dff712bc3438f92dee943261eb6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3708251ec3aa43eaa98995e679b48c9a",
            "placeholder": "​",
            "style": "IPY_MODEL_8f155570943741eaa1cf30100ed8ac07",
            "value": " 104M/104M [00:00&lt;00:00, 137MB/s]"
          }
        },
        "e08cc783c74a4f9cb92e30dbb04e027d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a76277b6285447479b088086a4c693f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666520bfeae14003a90fa48705e3bf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "131ebfb6c08d4cb3a5e9c1b75828296b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d51e371d127a4f419c6e18a89e01c7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3708251ec3aa43eaa98995e679b48c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f155570943741eaa1cf30100ed8ac07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}